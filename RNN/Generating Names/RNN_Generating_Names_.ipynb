{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKHbZ8aDa9Ko"
      },
      "source": [
        "### Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "CEE2KxBLa9K3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Ff97a6a9K5"
      },
      "source": [
        "# Our data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "juJX_eoua9K8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "start_token = \" \"\n",
        "\n",
        "with open(\"names.txt\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token+name for name in names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UthOuJwIa9K8",
        "outputId": "61198623-9ef3-4b60-a20e-ea53d2cd9766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n samples =  55691\n",
            " Aaban\n",
            " Amartya\n",
            " Aaruren\n",
            " Arijan\n",
            " Borna\n",
            " Chris\n",
            " Dattatri\n",
            " Falgu\n",
            " Gurumurthy\n",
            " Isaiarasu\n",
            " Janujan\n",
            " Kaustav\n",
            " Kavanan\n",
            " Likhith\n",
            " Mihirkiran\n",
            " Mithunraj\n",
            " Nrupen\n",
            " Nuwarshan\n",
            " Punithan\n",
            " Rajvardan\n",
            " Rathumithan\n",
            " Sanyam\n",
            " Sivanantham\n",
            " Sajibirunthan\n",
            " Sharinan\n",
            " Suhaenithan\n",
            " Tharnish\n",
            " Vaasanthi\n",
            " Vaheeshen\n",
            " Vishaonth\n",
            " Yogendhar\n",
            " Amuthaa\n",
            " Abeeshka\n",
            " Apira\n",
            " Balananthini\n",
            " Deepta\n",
            " Dhayanika\n",
            " Golbahar\n",
            " Harrini\n",
            " Jenu\n",
            " Kaamiya\n",
            " Kaneeshna\n",
            " Kunaisha\n",
            " Maina\n",
            " Manomani\n",
            " Namia\n",
            " Neranjana\n",
            " Padmakalyani\n",
            " Pireethiegaa\n",
            " Rishinila\n",
            " Rithyani\n",
            " Tenzing\n",
            " Thejaswari\n",
            " Vardhini\n",
            " Veeryaluxmy\n",
            " Yaashana\n"
          ]
        }
      ],
      "source": [
        "print ('n samples = ',len(names))\n",
        "for x in names[::1000]:\n",
        "    print (x)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WjDTgAiHa9K-",
        "outputId": "80376f9f-3888-4d2e-d16e-bce8855a1ed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max length = 26\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "MAX_LENGTH = max(map(len,names))\n",
        "print(\"max length =\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len,names)),bins=25);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-66sMKaka9K_"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need next to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CE89WO7Fa9LA",
        "outputId": "71710063-4c73-446e-8692-d3d7139f5667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_tokens =  55\n"
          ]
        }
      ],
      "source": [
        "#all unique characters go here\n",
        "tokens = set(''.join(names))\n",
        "\n",
        "tokens = list(tokens)\n",
        "\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens = ',n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sd2XKqFa9LD"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "HFFRor-pa9LF"
      },
      "outputs": [],
      "source": [
        "token_to_id = {symbol : index for symbol,index in zip(tokens,range(len(tokens)))}\n",
        "###YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7EbnJYrLa9LH",
        "outputId": "604603f2-67c5-43f0-d2d7-3acef8f543a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seems alright!\n"
          ]
        }
      ],
      "source": [
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "\n",
        "for i in range(n_tokens):\n",
        "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
        "\n",
        "print(\"Seems alright!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "KJl10sHna9LI"
      },
      "outputs": [],
      "source": [
        "def to_matrix(names,max_len=None,pad=0,dtype='int32'):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len,names))\n",
        "    names_ix = np.zeros([len(names),max_len],dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get,names[i]))\n",
        "        names_ix[i,:len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j838ZfoYa9LJ",
        "outputId": "63913430-208c-4f84-e127-945f19047ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Aaban\n",
            " Aaruren\n",
            " Borna\n",
            " Dattatri\n",
            " Gurumurthy\n",
            " Janujan\n",
            " Kavanan\n",
            " Mihirkiran\n",
            " Nrupen\n",
            " Punithan\n",
            " Rathumithan\n",
            " Sivanantham\n",
            " Sharinan\n",
            " Tharnish\n",
            " Vaheeshen\n",
            " Yogendhar\n",
            " Abeeshka\n",
            " Balananthini\n",
            " Dhayanika\n",
            " Harrini\n",
            " Kaamiya\n",
            " Kunaisha\n",
            " Manomani\n",
            " Neranjana\n",
            " Pireethiegaa\n",
            " Rithyani\n",
            " Thejaswari\n",
            " Veeryaluxmy\n",
            "[[46 10 36 17 36  7  0  0  0  0  0  0  0]\n",
            " [46 10 36 35 29 35 16  7  0  0  0  0  0]\n",
            " [46 27 37 35  7 36  0  0  0  0  0  0  0]\n",
            " [46  1 36 21 21 36 21 35  8  0  0  0  0]\n",
            " [46 51 29 35 29 30 29 35 21 25 19  0  0]\n",
            " [46 50 36  7 29 48 36  7  0  0  0  0  0]\n",
            " [46 32 36 53 36  7 36  7  0  0  0  0  0]\n",
            " [46 18  8 25  8 35 13  8 35 36  7  0  0]\n",
            " [46 15 35 29  3 16  7  0  0  0  0  0  0]\n",
            " [46 47 29  7  8 21 25 36  7  0  0  0  0]\n",
            " [46 11 36 21 25 29 30  8 21 25 36  7  0]\n",
            " [46 20  8 53 36  7 36  7 21 25 36 30  0]\n",
            " [46 20 25 36 35  8  7 36  7  0  0  0  0]\n",
            " [46 31 25 36 35  7  8 54 25  0  0  0  0]\n",
            " [46  2 36 25 16 16 54 25 16  7  0  0  0]\n",
            " [46 34 37 44 16  7 41 25 36 35  0  0  0]\n",
            " [46 10 17 16 16 54 25 13 36  0  0  0  0]\n",
            " [46 27 36 24 36  7 36  7 21 25  8  7  8]\n",
            " [46  1 25 36 19 36  7  8 13 36  0  0  0]\n",
            " [46 40 36 35 35  8  7  8  0  0  0  0  0]\n",
            " [46 32 36 36 30  8 19 36  0  0  0  0  0]\n",
            " [46 32 29  7 36  8 54 25 36  0  0  0  0]\n",
            " [46 18 36  7 37 30 36  7  8  0  0  0  0]\n",
            " [46 15 16 35 36  7 48 36  7 36  0  0  0]\n",
            " [46 47  8 35 16 16 21 25  8 16 44 36 36]\n",
            " [46 11  8 21 25 19 36  7  8  0  0  0  0]\n",
            " [46 31 25 16 48 36 54 38 36 35  8  0  0]\n",
            " [46  2 16 16 35 19 36 24 29 26 30 19  0]]\n"
          ]
        }
      ],
      "source": [
        "#Example: cast 4 random names to matrices, pad with zeros\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dCZm6X6a9LO"
      },
      "source": [
        "# Recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"./rnn.png\" width=480>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ItushrKQa9LR"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Concatenate,Dense,Embedding\n",
        "\n",
        "rnn_num_units = 64\n",
        "embedding_size = 16\n",
        "\n",
        "#Let's create layers for our recurrent network\n",
        "#Note: we create layers but we don't \"apply\" them yet\n",
        "embed_x = Embedding(n_tokens,embedding_size) # an embedding layer that converts character ids into embeddings\n",
        "\n",
        "\n",
        "#a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units,activation=\"relu\")\n",
        "###YOUR CODE HERE\n",
        "\n",
        "#a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(len(tokens),activation=\"softmax\")\n",
        "\n",
        "#Note: please either set the correct activation to Dense or write it manually in rnn_one_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "q47065NFa9LR"
      },
      "outputs": [],
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces next state and output\n",
        "    given prev input and previous state.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    Follow inline isntructions to complete the function.\n",
        "    \"\"\"\n",
        "    #convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t,[-1,1]))[:,0]\n",
        "    \n",
        "    #concatenate x embedding and previous h state\n",
        "   # x_and_h = Concatenate()([x_t_emb, h_t])\n",
        "    \n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)\n",
        "\n",
        "    ###YOUR CODE HERE\n",
        "    \n",
        "    #compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    #get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas,h_next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8dYcDBsa9LS"
      },
      "source": [
        "### RNN loop\n",
        "\n",
        "Once rnn_one_step is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aOSmoFbSa9LS"
      },
      "outputs": [],
      "source": [
        "input_sequence = tf.compat.v1.disable_eager_execution()\n",
        "input_sequence = tf.compat.v1.placeholder('int32',(MAX_LENGTH,None))\n",
        "batch_size = tf.shape(input_sequence)[1]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size,rnn_num_units]) #initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[t]\n",
        "    probas_next,h_next = rnn_one_step(x_t,h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "predicted_probas = tf.stack(predicted_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljruiKiza9LS"
      },
      "source": [
        "## RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "M6PWhwmBa9LT"
      },
      "outputs": [],
      "source": [
        "predictions_matrix = tf.reshape(predicted_probas[:-1],[-1,len(tokens)])\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[1:],[-1]), n_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hEmPrayAa9LU"
      },
      "outputs": [],
      "source": [
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "\n",
        "optimize = tf.compat.v1.train.AdamOptimizer().minimize(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUhI7x0a9LV"
      },
      "source": [
        "### The training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "NT4m9sdja9LV"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "s = keras.backend.get_session()\n",
        "s.run(tf.compat.v1.global_variables_initializer())\n",
        "history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "t8ELr8aWa9LV",
        "outputId": "be7f1351-56e6-4bc8-b048-1695018bfb51"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "for i in range(10000):\n",
        "    batch = to_matrix(sample(names,32),max_len=MAX_LENGTH)\n",
        "    loss_i,_ = s.run([loss,optimize],{input_sequence:batch})\n",
        "    \n",
        "    \n",
        "    history.append(loss_i)\n",
        "    if (i+1)%100==0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history,label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPOBd1z5a9LW"
      },
      "source": [
        "### RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xXUzkNNPa9LX"
      },
      "outputs": [],
      "source": [
        "x_t = tf.compat.v1.placeholder('int32',(None,))\n",
        "h_t = tf.Variable(np.zeros([1,rnn_num_units],'float32'))\n",
        "\n",
        "next_probs,next_h = rnn_one_step(x_t,h_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "8tECflQBa9LX"
      },
      "outputs": [],
      "source": [
        "def generate_sample(seed_phrase=' ',max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "        \n",
        "    parameters:\n",
        "        The phrase is set using the variable seed_phrase\n",
        "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.compat.v1.assign(h_t,h_t.initial_value))\n",
        "    \n",
        "    #feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.compat.v1.assign(h_t,next_h),{x_t:[ix]})\n",
        "    \n",
        "    #start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs,tf.compat.v1.assign(h_t,next_h)],{x_t:[x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens,p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "hFrsUAb0a9LX",
        "outputId": "f4438b00-9c1e-472c-a3d1-9aa115cb5829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Koshiranccccccccccccccccc\n",
            " Miruthinicccccccccccccccc\n",
            " Gelamianccccccccccccccccc\n",
            " Kisubancccccccccccccccccc\n",
            " Kayakranccccccccccccccccc\n",
            " Inithaccccccccccccccccccc\n",
            " Elidhaccccccccccccccccccc\n",
            " Nitvacccccccccccccccccccc\n",
            " Pagsh Prashaccccccccccccc\n",
            " Vendhanancccccccccccccccc\n",
            " Pugaccccccccccccccccccccc\n",
            " Mathuvananjagancccccccccc\n",
            " Puvasmccccccccccccccccccc\n",
            " Yumethccccccccccccccccccc\n",
            " Logendrencccccccccccccccc\n",
            " Gathulanacccccccccccccccc\n",
            " Ruthutrejancccccccccccccc\n",
            " Vegancccccccccccccccccccc\n",
            " Nelahcccccccccccccccccccc\n",
            " Peerthamurivaalancccccccc\n"
          ]
        }
      ],
      "source": [
        "for _ in range(20):\n",
        "    print(generate_sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "96KXjDBTa9LY",
        "outputId": "a2f8a986-bf59-442c-dacc-f4f07f79e30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Valamathankancccccccccccc\n",
            " Valanngcccccccccccccccccc\n",
            " Valumiramandamccccccccccc\n",
            " Valmithracccccccccccccccc\n",
            " Valilcccccccccccccccccccc\n",
            " Valashanccccccccccccccccc\n",
            " Valindicccccccccccccccccc\n",
            " Valaedacccccccccccccccccc\n",
            " Valininaccccccccccccccccc\n",
            " Valiskarccccccccccccccccc\n",
            " Valuloyanthcccccccccccccc\n",
            " Val Rukshaniccccccccccccc\n",
            " Vallikaprajatcccccccccccc\n",
            " Vallanivajccccccccccccccc\n",
            " Valelaneeranccccccccccccc\n",
            " Valawikamalcccccccccccccc\n",
            " Valamodhanccccccccccccccc\n",
            " Val priyenccccccccccccccc\n",
            " Valigalcccccccccccccccccc\n",
            " Valeyancccccccccccccccccc\n",
            " Valikaccccccccccccccccccc\n",
            " Val Puvathacccccccccccccc\n",
            " Valiscccccccccccccccccccc\n",
            " Valanyacccccccccccccccccc\n",
            " Valcccccccccccccccccccccc\n",
            " Valanchethicccccccccccccc\n",
            " Valveshancccccccccccccccc\n",
            " Valiyatvacccccccccccccccc\n",
            " Valamishacccccccccccccccc\n",
            " Valavishacccccccccccccccc\n",
            " Valishaamanantccccccccccc\n",
            " Valihigaccccccccccccccccc\n",
            " Valinimoncccccccccccccccc\n",
            " Valajevancccccccccccccccc\n",
            " Valmicccccccccccccccccccc\n",
            " Valilaycccccccccccccccccc\n",
            " Valaniccccccccccccccccccc\n",
            " Valmanyaccccccccccccccccc\n",
            " Valvialabitcccccccccccccc\n",
            " Valasukaccccccccccccccccc\n",
            " Valishkaccccccccccccccccc\n",
            " Valikancccccccccccccccccc\n",
            " Valajeevimicccccccccccccc\n",
            " Valieepcccccccccccccccccc\n",
            " Valunhnaccccccccccccccccc\n",
            " Valeshccccccccccccccccccc\n",
            " Valnesacccccccccccccccccc\n",
            " Valambhatcccccccccccccccc\n",
            " Valijaccccccccccccccccccc\n",
            " Valayashanccccccccccccccc\n"
          ]
        }
      ],
      "source": [
        "for _ in range(50):\n",
        "    print(generate_sample(' Val'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pvSMBXIa9LZ"
      },
      "source": [
        "### Try it out!\n",
        "\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* Ikea catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "8GBtXoM4a9LZ"
      },
      "source": [
        "### Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from keras, there's also a friendly tensorflow API for recurrent neural nets. It's based around the symbolic loop function (aka [scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "97ItZcVZa9La",
        "outputId": "452a83bf-b3f3-47a5-bf60-65b11819f004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\jayan\\anaconda3\\lib\\site-packages\\keras\\layers\\rnn\\legacy_cells.py:429: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jayan\\AppData\\Local\\Temp\\ipykernel_2316\\3929012380.py:11: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = CustomRNN(rnn_num_units)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 10, 55)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class CustomRNN(tf.compat.v1.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self,input,state):\n",
        "        return rnn_one_step(input[:,0],state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "\n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.compat.v1.placeholder('float32',(None,None))\n",
        "    \n",
        "predicted_probas, last_state = tf.compat.v1.nn.dynamic_rnn(cell,input_sequence[:,:,None],\n",
        "                                                 time_major=True,dtype='float32')\n",
        "sess = tf.compat.v1.Session()\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess.run(init)\n",
        "with sess.as_default():\n",
        "    print(predicted_probas.eval({input_sequence:to_matrix(names[:10],max_len=50)}).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoY-jNfGa9La"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use the all the pre-implemented RNN cells:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NeSpPIvBa9La",
        "outputId": "7cbf6b65-d7bc-49ac-ebab-a05e04bd619e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\n",
            "BasicRNNCell\n",
            "GRUCell\n",
            "LSTMCell\n",
            "MultiRNNCell\n",
            "RNNCell\n"
          ]
        }
      ],
      "source": [
        "for obj in dir(tf.compat.v1.nn.rnn_cell):\n",
        "    if obj.endswith('Cell'):\n",
        "        print (obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "aq3n6rmla9Lb",
        "outputId": "f751aa3d-c6ec-4458-81ff-3743c621e79c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM visible states[time,batch,unit]: Tensor(\"rnn_2/transpose_1:0\", shape=(None, None, 64), dtype=float32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jayan\\AppData\\Local\\Temp\\ipykernel_2316\\3766526553.py:5: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(rnn_num_units)\n"
          ]
        }
      ],
      "source": [
        "input_sequence = tf.compat.v1.placeholder('int32',(None,None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "cell = tf.compat.v1.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence,last_state = tf.compat.v1.nn.dynamic_rnn(cell,inputs_embedded,dtype='float32')\n",
        "\n",
        "print('LSTM visible states[time,batch,unit]:', state_sequence)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "6_RNN_Generating Names .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "51d2dbc107e90016ff58d506d19dfa66132cafa2ebfedbf9f4d98cf0f5094b18"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
