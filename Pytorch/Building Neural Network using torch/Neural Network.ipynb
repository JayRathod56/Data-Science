{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules loaded\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "print(\"Modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([7])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Linear weights: Parameter containing:\n",
      "tensor([[ 0.0352, -0.0019,  0.0276,  ...,  0.0038, -0.0181,  0.0119],\n",
      "        [-0.0243, -0.0040,  0.0111,  ...,  0.0047,  0.0204,  0.0301],\n",
      "        [ 0.0155, -0.0048, -0.0231,  ..., -0.0274, -0.0220,  0.0199],\n",
      "        ...,\n",
      "        [ 0.0328, -0.0177,  0.0161,  ..., -0.0144, -0.0251, -0.0011],\n",
      "        [-0.0026,  0.0220, -0.0269,  ..., -0.0010,  0.0203,  0.0187],\n",
      "        [-0.0158, -0.0356, -0.0045,  ..., -0.0121, -0.0208, -0.0275]],\n",
      "       requires_grad=True) \n",
      "\n",
      "First Linear weights: Parameter containing:\n",
      "tensor([-1.4680e-02, -1.5305e-02, -1.2052e-02, -2.0271e-02,  1.1510e-02,\n",
      "         2.0742e-02,  1.1668e-02, -3.5465e-02,  3.2835e-02,  1.1606e-02,\n",
      "        -3.3731e-02, -3.4751e-02,  8.6885e-03,  2.0563e-02,  1.7087e-02,\n",
      "         3.1093e-02, -2.3801e-02,  1.9098e-03, -1.4252e-02,  1.9442e-02,\n",
      "        -1.7422e-02,  2.0704e-02, -1.0668e-02,  4.1207e-03,  2.8590e-02,\n",
      "        -1.1370e-02, -7.6407e-03, -1.2068e-02, -3.0384e-02,  3.3704e-03,\n",
      "        -3.2363e-03,  2.2905e-02,  1.9120e-03, -1.6735e-02, -7.5266e-03,\n",
      "        -3.5543e-02,  2.6894e-03,  1.0212e-02,  4.1533e-03, -2.3747e-02,\n",
      "         3.4498e-02,  1.8859e-03,  1.3741e-03,  2.1822e-03,  9.3377e-03,\n",
      "         1.2614e-02,  3.1168e-02,  8.1387e-03,  1.0293e-02, -1.1906e-03,\n",
      "        -8.2592e-04, -2.7942e-02, -2.3198e-02,  2.9067e-02, -3.1575e-02,\n",
      "        -3.0035e-02,  2.5476e-02,  1.0439e-02,  3.2693e-02, -2.6055e-02,\n",
      "        -4.4556e-03, -1.0642e-02,  1.7020e-02,  8.9081e-03,  2.3806e-02,\n",
      "         3.1641e-02, -1.2204e-02, -1.7131e-03,  2.0801e-02,  3.1619e-03,\n",
      "         2.8240e-02, -2.2851e-03,  3.5367e-02, -3.5006e-02,  1.4429e-02,\n",
      "         3.5683e-02,  1.9819e-02, -7.7540e-03, -2.4737e-02, -2.6174e-03,\n",
      "         3.3966e-02, -3.2552e-02, -3.5176e-02,  2.5269e-02,  6.8058e-03,\n",
      "        -5.6574e-03, -3.3326e-02,  8.2046e-03, -6.1712e-03,  1.5799e-02,\n",
      "        -3.3821e-02, -3.4154e-02, -1.8760e-02, -1.9894e-04,  3.3901e-02,\n",
      "         1.0602e-03, -2.8710e-02,  2.3293e-02, -3.3286e-02, -2.7277e-02,\n",
      "        -3.1764e-02, -2.5991e-02, -8.9212e-03, -2.7797e-02,  7.5424e-03,\n",
      "         1.5114e-02,  1.2769e-02,  3.2156e-02, -2.1669e-02,  2.7684e-02,\n",
      "         2.9494e-03,  1.1720e-02, -1.9853e-02, -1.8647e-02, -2.8545e-02,\n",
      "         1.8340e-02,  3.0924e-02,  1.0329e-02, -1.8832e-02,  2.0308e-02,\n",
      "         6.8328e-03,  1.9004e-02, -2.9259e-02,  3.5349e-02,  2.4432e-02,\n",
      "        -1.6397e-02,  2.1103e-02, -1.3642e-02,  2.7964e-02,  1.5907e-02,\n",
      "         1.1705e-02,  2.2328e-02, -2.9334e-02,  9.2503e-03, -3.2192e-02,\n",
      "         3.4806e-02,  3.4713e-02, -5.5619e-06, -2.5111e-02, -2.6845e-02,\n",
      "         3.7627e-03, -3.4903e-02, -2.3175e-02, -9.9063e-03,  2.9111e-02,\n",
      "        -1.6612e-02, -1.7422e-02, -2.6691e-02, -2.9708e-02, -1.2298e-02,\n",
      "         6.2957e-03,  7.1578e-03,  3.1644e-02,  2.5150e-02,  1.0560e-02,\n",
      "        -2.7926e-02,  1.9058e-02,  1.9836e-02, -1.9602e-02,  1.8042e-02,\n",
      "         1.0652e-02, -3.4462e-02, -2.3901e-02,  1.8773e-03, -4.9061e-04,\n",
      "         1.9866e-02, -9.9783e-03,  3.1066e-02,  2.4543e-02, -8.2789e-03,\n",
      "         1.1553e-03, -1.8847e-02, -2.4971e-02, -1.3601e-02, -5.9641e-03,\n",
      "         3.6501e-03,  1.1567e-02,  9.4249e-03,  1.4404e-02, -1.4025e-02,\n",
      "        -3.3099e-02, -1.9801e-02, -6.8946e-03,  3.4057e-02, -3.5497e-02,\n",
      "         3.1543e-02,  1.0069e-02,  7.2651e-03, -3.0122e-02, -2.2445e-05,\n",
      "        -3.1089e-02,  1.4782e-02, -3.5000e-02,  1.9881e-02, -3.3582e-02,\n",
      "        -4.5188e-03,  3.4555e-02,  1.2398e-02, -5.0337e-03, -2.5906e-02,\n",
      "         3.2880e-02,  2.6083e-02,  1.2846e-03,  3.3751e-02, -1.2540e-02,\n",
      "         4.7701e-04,  3.3346e-02, -4.3392e-03,  2.4779e-02,  2.2480e-02,\n",
      "        -2.0535e-02,  3.0439e-03, -2.4049e-02, -1.6133e-02, -1.3822e-02,\n",
      "        -1.6713e-02, -1.0947e-03, -8.7353e-03, -6.5605e-03,  1.0786e-02,\n",
      "        -2.5980e-02, -3.4565e-02,  1.6210e-02,  1.5332e-02, -3.4082e-03,\n",
      "         2.0870e-02,  1.1377e-03,  2.0915e-02, -2.5876e-02,  3.4516e-02,\n",
      "        -1.4668e-02, -2.5343e-02, -3.3706e-02, -7.6420e-03, -3.0040e-02,\n",
      "         6.4052e-03,  1.0190e-02, -1.1289e-02,  5.5403e-04, -1.9853e-02,\n",
      "         1.8246e-02, -4.7934e-03,  1.3978e-02, -3.3778e-02, -9.3542e-03,\n",
      "         1.1571e-02,  3.4429e-02,  3.4154e-03, -3.3855e-02, -2.1143e-02,\n",
      "         3.3254e-02, -1.9707e-03,  1.4411e-02, -3.3397e-02,  7.1999e-04,\n",
      "         1.6923e-02,  3.1492e-02, -1.2792e-02, -5.2458e-03, -1.6169e-02,\n",
      "        -1.2673e-02, -6.0018e-03,  2.2773e-02, -2.2807e-03, -8.4885e-03,\n",
      "        -1.7501e-02, -3.4405e-02, -4.2783e-03, -5.6615e-03,  3.0230e-02,\n",
      "         1.9103e-02, -3.1372e-02, -1.7847e-02, -1.6449e-02,  2.8796e-02,\n",
      "         6.9937e-03,  1.9005e-02,  9.6813e-03, -2.8657e-02, -5.8331e-03,\n",
      "        -2.8923e-02,  6.6480e-04, -2.2894e-02, -2.1731e-02, -3.1612e-02,\n",
      "        -3.5593e-02,  1.3435e-02,  3.4256e-02, -3.3307e-02, -2.2983e-02,\n",
      "         3.0700e-02,  2.7688e-02, -8.1214e-03, -1.3415e-02, -2.7833e-02,\n",
      "        -2.1076e-02, -2.5388e-02, -2.0345e-02, -3.3247e-02, -3.2243e-02,\n",
      "         2.7314e-02,  7.6726e-03,  2.9660e-03,  1.1546e-02,  1.9602e-02,\n",
      "        -3.2363e-02, -2.3431e-02,  6.5964e-03, -2.8041e-03,  1.2168e-02,\n",
      "        -1.8094e-03, -2.0875e-02, -3.5011e-02, -1.0809e-03, -2.9981e-02,\n",
      "        -3.7122e-03,  2.3761e-02,  1.8280e-02, -1.2870e-02,  1.2783e-02,\n",
      "         2.8012e-02, -4.2315e-03, -3.0621e-02, -2.7088e-03, -1.2601e-02,\n",
      "        -1.3567e-02,  2.7648e-02, -1.9449e-02,  2.1713e-02, -2.6754e-02,\n",
      "        -1.0705e-02,  5.8723e-03,  2.9996e-02,  2.3645e-02, -2.4373e-02,\n",
      "         3.1295e-02,  1.8485e-02, -3.1300e-02,  1.7247e-02,  1.2061e-03,\n",
      "        -2.3935e-02, -2.9791e-02, -6.1724e-03,  6.3672e-03, -1.6109e-02,\n",
      "         3.4253e-02, -1.2792e-02, -2.5978e-02,  2.4455e-03, -3.2506e-02,\n",
      "        -8.1424e-03,  1.4107e-03, -3.1309e-02, -1.0133e-02,  1.7446e-02,\n",
      "        -3.3067e-02,  2.6096e-02,  2.0982e-02,  3.4379e-02, -1.1459e-02,\n",
      "         4.2340e-03, -3.0988e-03, -2.4925e-02, -2.1021e-02, -1.0625e-02,\n",
      "         3.4111e-03, -3.0447e-02,  1.2532e-03,  3.0101e-02,  6.3474e-03,\n",
      "        -1.7601e-02, -1.6542e-02,  3.0113e-02, -1.0697e-02, -2.9471e-02,\n",
      "         4.9824e-03,  1.2670e-02, -7.1956e-03,  3.4187e-02, -1.8309e-02,\n",
      "        -3.3712e-02,  1.4095e-02, -6.3160e-03,  3.4858e-02, -1.4057e-02,\n",
      "         2.6326e-02, -2.6711e-03,  1.6050e-03,  9.5460e-03, -2.4777e-02,\n",
      "         3.4835e-02, -1.7618e-02,  1.9081e-02,  1.6595e-02,  1.4324e-02,\n",
      "        -3.1879e-02,  1.9421e-02,  1.4682e-02,  1.2012e-02,  3.5116e-02,\n",
      "         2.5019e-02,  2.5753e-02,  1.5004e-02,  2.6859e-03, -1.5901e-02,\n",
      "        -2.3405e-02, -5.3968e-03, -7.3887e-03,  2.5660e-03, -1.8084e-02,\n",
      "        -2.0307e-02,  3.5333e-02,  1.1652e-02,  2.0457e-02,  1.4970e-02,\n",
      "        -1.8486e-02, -2.1907e-02, -3.2668e-02, -3.6212e-03, -3.4845e-02,\n",
      "        -1.5088e-02,  2.4201e-03,  9.2651e-03,  3.1235e-02,  1.9270e-02,\n",
      "        -2.8768e-02,  6.3002e-03, -2.5247e-02,  8.7421e-03, -3.0631e-02,\n",
      "        -2.1401e-02, -1.3774e-02, -2.7536e-02,  3.1567e-02, -3.0796e-03,\n",
      "        -2.3322e-02, -1.0058e-02, -1.7088e-02,  1.5827e-02, -2.8409e-02,\n",
      "        -2.9692e-02,  2.3850e-02,  1.0301e-02, -2.6792e-03, -1.8347e-02,\n",
      "        -5.9936e-03,  1.5192e-02,  2.1717e-02,  1.6512e-02,  2.2542e-02,\n",
      "         2.8046e-02, -2.2765e-02, -2.5555e-02, -1.7464e-03,  3.2054e-02,\n",
      "         4.1485e-03,  1.2073e-02, -5.3881e-03, -2.5610e-02,  2.9456e-02,\n",
      "        -1.2021e-02,  4.3847e-03,  1.3293e-03, -5.2898e-03, -2.6199e-02,\n",
      "        -1.4786e-02, -4.8807e-03,  1.9372e-02, -2.1942e-02, -1.8584e-02,\n",
      "        -1.7102e-02, -1.6082e-02,  5.3375e-03, -8.7895e-03, -2.8557e-02,\n",
      "         2.9636e-02,  2.2778e-02, -6.0099e-04, -1.7141e-02,  1.4170e-03,\n",
      "        -3.4741e-02, -3.1664e-03, -1.1105e-02,  2.5287e-02,  3.4194e-02,\n",
      "         1.8626e-02,  3.5577e-03,  1.7074e-02, -2.7329e-02, -3.1815e-02,\n",
      "         6.6360e-03, -4.7356e-03, -2.8526e-02, -1.2863e-03, -8.6322e-03,\n",
      "         1.1591e-02,  1.6597e-02, -1.6535e-02, -1.0253e-02,  1.2779e-03,\n",
      "         1.6855e-02,  3.4058e-02, -1.7839e-02, -5.2433e-03,  1.5954e-02,\n",
      "        -8.9690e-03, -7.8413e-03,  5.2435e-03, -9.6259e-03,  2.9261e-02,\n",
      "        -2.1684e-02,  1.2999e-02], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
    "print(f\"First Linear weights: {model.linear_relu_stack[0].bias} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.2382, -0.3125,  0.4690, -0.3651, -0.1723,  0.2923, -0.1185,  0.0232,\n",
      "          0.1019, -0.0761, -0.1298, -0.0152, -0.4816,  0.0981,  0.2682, -0.4743,\n",
      "          0.4099, -0.0503, -0.0365,  0.0605],\n",
      "        [ 0.5000, -0.1458,  0.2309, -0.0489, -0.1231, -0.0740,  0.1045,  0.0135,\n",
      "          0.2630,  0.0781, -0.1491,  0.0503, -0.3803,  0.0650,  0.0217, -0.0301,\n",
      "          0.6531,  0.2403, -0.0524, -0.1480],\n",
      "        [ 0.5194,  0.1616,  0.1917, -0.2057, -0.0661, -0.3417,  0.2378, -0.1309,\n",
      "          0.1831,  0.2072, -0.0525,  0.1594, -0.1588, -0.0906,  0.1708,  0.0611,\n",
      "          0.2773,  0.1345,  0.2013, -0.2320]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.2382, 0.0000, 0.4690, 0.0000, 0.0000, 0.2923, 0.0000, 0.0232, 0.1019,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0981, 0.2682, 0.0000, 0.4099, 0.0000,\n",
      "         0.0000, 0.0605],\n",
      "        [0.5000, 0.0000, 0.2309, 0.0000, 0.0000, 0.0000, 0.1045, 0.0135, 0.2630,\n",
      "         0.0781, 0.0000, 0.0503, 0.0000, 0.0650, 0.0217, 0.0000, 0.6531, 0.2403,\n",
      "         0.0000, 0.0000],\n",
      "        [0.5194, 0.1616, 0.1917, 0.0000, 0.0000, 0.0000, 0.2378, 0.0000, 0.1831,\n",
      "         0.2072, 0.0000, 0.1594, 0.0000, 0.0000, 0.1708, 0.0611, 0.2773, 0.1345,\n",
      "         0.2013, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "flatten,\n",
    "layer1,\n",
    "nn.ReLU(),\n",
    "nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0352, -0.0019,  0.0276,  ...,  0.0038, -0.0181,  0.0119],\n",
      "        [-0.0243, -0.0040,  0.0111,  ...,  0.0047,  0.0204,  0.0301]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0147, -0.0153], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0096,  0.0330, -0.0159,  ...,  0.0287, -0.0343, -0.0419],\n",
      "        [-0.0367, -0.0219, -0.0334,  ...,  0.0017, -0.0235,  0.0381]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0037, -0.0163], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0319, -0.0227, -0.0025,  ..., -0.0345,  0.0274, -0.0070],\n",
      "        [-0.0408,  0.0273,  0.0403,  ..., -0.0149, -0.0216, -0.0152]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0332, 0.0393], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your knowledge\n",
    "A. The base class for all neural network modules in PyTorch is torch.nn.Module\n",
    "1. True\n",
    "2. False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51d2dbc107e90016ff58d506d19dfa66132cafa2ebfedbf9f4d98cf0f5094b18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
