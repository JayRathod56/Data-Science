{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayan\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4b8fcc2f1c4d818d8dec64d28c4038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce2fe20ae114c909a6aa32bf13511bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc18e3c009c4055addfe765b8cced94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a1dbdc3f6b4f95815968730d63ce02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork()\n",
    "print(\"NN Model Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameters initialised\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "print(\"hyperparameters initialised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\\n",
    "    n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.483855 [    0/60000]\n",
      "loss: 1.537628 [ 6400/60000]\n",
      "loss: 1.381934 [12800/60000]\n",
      "loss: 1.497222 [19200/60000]\n",
      "loss: 1.427269 [25600/60000]\n",
      "loss: 1.553237 [32000/60000]\n",
      "loss: 1.392775 [38400/60000]\n",
      "loss: 1.431867 [44800/60000]\n",
      "loss: 1.495929 [51200/60000]\n",
      "loss: 1.417867 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 0.023344     n\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.454549 [    0/60000]\n",
      "loss: 1.510757 [ 6400/60000]\n",
      "loss: 1.353127 [12800/60000]\n",
      "loss: 1.475487 [19200/60000]\n",
      "loss: 1.408865 [25600/60000]\n",
      "loss: 1.536106 [32000/60000]\n",
      "loss: 1.373379 [38400/60000]\n",
      "loss: 1.410586 [44800/60000]\n",
      "loss: 1.475191 [51200/60000]\n",
      "loss: 1.401963 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 0.023037     n\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.428504 [    0/60000]\n",
      "loss: 1.486658 [ 6400/60000]\n",
      "loss: 1.327846 [12800/60000]\n",
      "loss: 1.457725 [19200/60000]\n",
      "loss: 1.394172 [25600/60000]\n",
      "loss: 1.521425 [32000/60000]\n",
      "loss: 1.356251 [38400/60000]\n",
      "loss: 1.392285 [44800/60000]\n",
      "loss: 1.456566 [51200/60000]\n",
      "loss: 1.387884 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 0.022766     n\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.405161 [    0/60000]\n",
      "loss: 1.465309 [ 6400/60000]\n",
      "loss: 1.305606 [12800/60000]\n",
      "loss: 1.442867 [19200/60000]\n",
      "loss: 1.381416 [25600/60000]\n",
      "loss: 1.507908 [32000/60000]\n",
      "loss: 1.340465 [38400/60000]\n",
      "loss: 1.376265 [44800/60000]\n",
      "loss: 1.420938 [51200/60000]\n",
      "loss: 1.305887 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 0.021930     n\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.373291 [    0/60000]\n",
      "loss: 1.444066 [ 6400/60000]\n",
      "loss: 1.250450 [12800/60000]\n",
      "loss: 1.375660 [19200/60000]\n",
      "loss: 1.363850 [25600/60000]\n",
      "loss: 1.404127 [32000/60000]\n",
      "loss: 1.347267 [38400/60000]\n",
      "loss: 1.341892 [44800/60000]\n",
      "loss: 1.373666 [51200/60000]\n",
      "loss: 1.261148 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.021544     n\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.348996 [    0/60000]\n",
      "loss: 1.419812 [ 6400/60000]\n",
      "loss: 1.219937 [12800/60000]\n",
      "loss: 1.354310 [19200/60000]\n",
      "loss: 1.347362 [25600/60000]\n",
      "loss: 1.380749 [32000/60000]\n",
      "loss: 1.332402 [38400/60000]\n",
      "loss: 1.323761 [44800/60000]\n",
      "loss: 1.354198 [51200/60000]\n",
      "loss: 1.236767 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.021221     n\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.324609 [    0/60000]\n",
      "loss: 1.397832 [ 6400/60000]\n",
      "loss: 1.192155 [12800/60000]\n",
      "loss: 1.336017 [19200/60000]\n",
      "loss: 1.330340 [25600/60000]\n",
      "loss: 1.358941 [32000/60000]\n",
      "loss: 1.317691 [38400/60000]\n",
      "loss: 1.306559 [44800/60000]\n",
      "loss: 1.335045 [51200/60000]\n",
      "loss: 1.212615 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 0.020907     n\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.300649 [    0/60000]\n",
      "loss: 1.376776 [ 6400/60000]\n",
      "loss: 1.165094 [12800/60000]\n",
      "loss: 1.318413 [19200/60000]\n",
      "loss: 1.313349 [25600/60000]\n",
      "loss: 1.336674 [32000/60000]\n",
      "loss: 1.303106 [38400/60000]\n",
      "loss: 1.290354 [44800/60000]\n",
      "loss: 1.315338 [51200/60000]\n",
      "loss: 1.188184 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.020599     n\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.276268 [    0/60000]\n",
      "loss: 1.356783 [ 6400/60000]\n",
      "loss: 1.138947 [12800/60000]\n",
      "loss: 1.301541 [19200/60000]\n",
      "loss: 1.296115 [25600/60000]\n",
      "loss: 1.314588 [32000/60000]\n",
      "loss: 1.289189 [38400/60000]\n",
      "loss: 1.275256 [44800/60000]\n",
      "loss: 1.295253 [51200/60000]\n",
      "loss: 1.164523 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 0.020305     n\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.252054 [    0/60000]\n",
      "loss: 1.337960 [ 6400/60000]\n",
      "loss: 1.113733 [12800/60000]\n",
      "loss: 1.286078 [19200/60000]\n",
      "loss: 1.279620 [25600/60000]\n",
      "loss: 1.293648 [32000/60000]\n",
      "loss: 1.275866 [38400/60000]\n",
      "loss: 1.261777 [44800/60000]\n",
      "loss: 1.275453 [51200/60000]\n",
      "loss: 1.142947 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.020034     n\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.228652 [    0/60000]\n",
      "loss: 1.321115 [ 6400/60000]\n",
      "loss: 1.090046 [12800/60000]\n",
      "loss: 1.271658 [19200/60000]\n",
      "loss: 1.264623 [25600/60000]\n",
      "loss: 1.275167 [32000/60000]\n",
      "loss: 1.263161 [38400/60000]\n",
      "loss: 1.249686 [44800/60000]\n",
      "loss: 1.257454 [51200/60000]\n",
      "loss: 1.124256 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 0.019794     n\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.206731 [    0/60000]\n",
      "loss: 1.306920 [ 6400/60000]\n",
      "loss: 1.068999 [12800/60000]\n",
      "loss: 1.258373 [19200/60000]\n",
      "loss: 1.252433 [25600/60000]\n",
      "loss: 1.259653 [32000/60000]\n",
      "loss: 1.251181 [38400/60000]\n",
      "loss: 1.238754 [44800/60000]\n",
      "loss: 1.242212 [51200/60000]\n",
      "loss: 1.108149 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 0.019583     n\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.187196 [    0/60000]\n",
      "loss: 1.294785 [ 6400/60000]\n",
      "loss: 1.050338 [12800/60000]\n",
      "loss: 1.246356 [19200/60000]\n",
      "loss: 1.241895 [25600/60000]\n",
      "loss: 1.246853 [32000/60000]\n",
      "loss: 1.239537 [38400/60000]\n",
      "loss: 1.229422 [44800/60000]\n",
      "loss: 1.228781 [51200/60000]\n",
      "loss: 1.094729 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.019396     n\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.169215 [    0/60000]\n",
      "loss: 1.283688 [ 6400/60000]\n",
      "loss: 1.033649 [12800/60000]\n",
      "loss: 1.216187 [19200/60000]\n",
      "loss: 1.231264 [25600/60000]\n",
      "loss: 1.116120 [32000/60000]\n",
      "loss: 1.159478 [38400/60000]\n",
      "loss: 1.083588 [44800/60000]\n",
      "loss: 1.148477 [51200/60000]\n",
      "loss: 1.007291 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.018135     n\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.054318 [    0/60000]\n",
      "loss: 1.252992 [ 6400/60000]\n",
      "loss: 0.948648 [12800/60000]\n",
      "loss: 1.181471 [19200/60000]\n",
      "loss: 1.220979 [25600/60000]\n",
      "loss: 1.074355 [32000/60000]\n",
      "loss: 1.134203 [38400/60000]\n",
      "loss: 1.050739 [44800/60000]\n",
      "loss: 1.122385 [51200/60000]\n",
      "loss: 0.979620 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.017681     n\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.020852 [    0/60000]\n",
      "loss: 1.223545 [ 6400/60000]\n",
      "loss: 0.922726 [12800/60000]\n",
      "loss: 1.159563 [19200/60000]\n",
      "loss: 1.197899 [25600/60000]\n",
      "loss: 1.042653 [32000/60000]\n",
      "loss: 1.110746 [38400/60000]\n",
      "loss: 1.022083 [44800/60000]\n",
      "loss: 1.097751 [51200/60000]\n",
      "loss: 0.955443 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.017278     n\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.991609 [    0/60000]\n",
      "loss: 1.197628 [ 6400/60000]\n",
      "loss: 0.899829 [12800/60000]\n",
      "loss: 1.140529 [19200/60000]\n",
      "loss: 1.177555 [25600/60000]\n",
      "loss: 1.016626 [32000/60000]\n",
      "loss: 1.089261 [38400/60000]\n",
      "loss: 0.997229 [44800/60000]\n",
      "loss: 1.076242 [51200/60000]\n",
      "loss: 0.934477 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 0.016939     n\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.966407 [    0/60000]\n",
      "loss: 1.177055 [ 6400/60000]\n",
      "loss: 0.881224 [12800/60000]\n",
      "loss: 1.125665 [19200/60000]\n",
      "loss: 1.160456 [25600/60000]\n",
      "loss: 0.995638 [32000/60000]\n",
      "loss: 1.018622 [38400/60000]\n",
      "loss: 0.881901 [44800/60000]\n",
      "loss: 0.943466 [51200/60000]\n",
      "loss: 0.873993 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.015419     n\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.802564 [    0/60000]\n",
      "loss: 1.051308 [ 6400/60000]\n",
      "loss: 0.800985 [12800/60000]\n",
      "loss: 1.124247 [19200/60000]\n",
      "loss: 0.981975 [25600/60000]\n",
      "loss: 0.873523 [32000/60000]\n",
      "loss: 0.960032 [38400/60000]\n",
      "loss: 0.814635 [44800/60000]\n",
      "loss: 0.895187 [51200/60000]\n",
      "loss: 0.835840 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.014670     n\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.741385 [    0/60000]\n",
      "loss: 0.990983 [ 6400/60000]\n",
      "loss: 0.754479 [12800/60000]\n",
      "loss: 1.097065 [19200/60000]\n",
      "loss: 0.928348 [25600/60000]\n",
      "loss: 0.840180 [32000/60000]\n",
      "loss: 0.919316 [38400/60000]\n",
      "loss: 0.777737 [44800/60000]\n",
      "loss: 0.863363 [51200/60000]\n",
      "loss: 0.807411 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.014100     n\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.698954 [    0/60000]\n",
      "loss: 0.945796 [ 6400/60000]\n",
      "loss: 0.719457 [12800/60000]\n",
      "loss: 1.072060 [19200/60000]\n",
      "loss: 0.892164 [25600/60000]\n",
      "loss: 0.815616 [32000/60000]\n",
      "loss: 0.885022 [38400/60000]\n",
      "loss: 0.753175 [44800/60000]\n",
      "loss: 0.841821 [51200/60000]\n",
      "loss: 0.785252 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.013676     n\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.667186 [    0/60000]\n",
      "loss: 0.912773 [ 6400/60000]\n",
      "loss: 0.693879 [12800/60000]\n",
      "loss: 1.050916 [19200/60000]\n",
      "loss: 0.869802 [25600/60000]\n",
      "loss: 0.797650 [32000/60000]\n",
      "loss: 0.859757 [38400/60000]\n",
      "loss: 0.737264 [44800/60000]\n",
      "loss: 0.827732 [51200/60000]\n",
      "loss: 0.768135 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.013371     n\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.643573 [    0/60000]\n",
      "loss: 0.888657 [ 6400/60000]\n",
      "loss: 0.675045 [12800/60000]\n",
      "loss: 1.033731 [19200/60000]\n",
      "loss: 0.857092 [25600/60000]\n",
      "loss: 0.783376 [32000/60000]\n",
      "loss: 0.839952 [38400/60000]\n",
      "loss: 0.727017 [44800/60000]\n",
      "loss: 0.818039 [51200/60000]\n",
      "loss: 0.752693 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.013134     n\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.625092 [    0/60000]\n",
      "loss: 0.870151 [ 6400/60000]\n",
      "loss: 0.660044 [12800/60000]\n",
      "loss: 1.018756 [19200/60000]\n",
      "loss: 0.847570 [25600/60000]\n",
      "loss: 0.771627 [32000/60000]\n",
      "loss: 0.823553 [38400/60000]\n",
      "loss: 0.720569 [44800/60000]\n",
      "loss: 0.811467 [51200/60000]\n",
      "loss: 0.738552 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.012936     n\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.609559 [    0/60000]\n",
      "loss: 0.855080 [ 6400/60000]\n",
      "loss: 0.647234 [12800/60000]\n",
      "loss: 1.005737 [19200/60000]\n",
      "loss: 0.838849 [25600/60000]\n",
      "loss: 0.761524 [32000/60000]\n",
      "loss: 0.809047 [38400/60000]\n",
      "loss: 0.716176 [44800/60000]\n",
      "loss: 0.806400 [51200/60000]\n",
      "loss: 0.725578 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.012762     n\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.595626 [    0/60000]\n",
      "loss: 0.841820 [ 6400/60000]\n",
      "loss: 0.635903 [12800/60000]\n",
      "loss: 0.994250 [19200/60000]\n",
      "loss: 0.831026 [25600/60000]\n",
      "loss: 0.752178 [32000/60000]\n",
      "loss: 0.796242 [38400/60000]\n",
      "loss: 0.713426 [44800/60000]\n",
      "loss: 0.802640 [51200/60000]\n",
      "loss: 0.713804 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.012607     n\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.583046 [    0/60000]\n",
      "loss: 0.830030 [ 6400/60000]\n",
      "loss: 0.625747 [12800/60000]\n",
      "loss: 0.984128 [19200/60000]\n",
      "loss: 0.823840 [25600/60000]\n",
      "loss: 0.744322 [32000/60000]\n",
      "loss: 0.784988 [38400/60000]\n",
      "loss: 0.711818 [44800/60000]\n",
      "loss: 0.799416 [51200/60000]\n",
      "loss: 0.703199 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.012469     n\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.571608 [    0/60000]\n",
      "loss: 0.819597 [ 6400/60000]\n",
      "loss: 0.616540 [12800/60000]\n",
      "loss: 0.974591 [19200/60000]\n",
      "loss: 0.816955 [25600/60000]\n",
      "loss: 0.737336 [32000/60000]\n",
      "loss: 0.775043 [38400/60000]\n",
      "loss: 0.711111 [44800/60000]\n",
      "loss: 0.796899 [51200/60000]\n",
      "loss: 0.693778 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.012343     n\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.561035 [    0/60000]\n",
      "loss: 0.810243 [ 6400/60000]\n",
      "loss: 0.608170 [12800/60000]\n",
      "loss: 0.965562 [19200/60000]\n",
      "loss: 0.810998 [25600/60000]\n",
      "loss: 0.730659 [32000/60000]\n",
      "loss: 0.766376 [38400/60000]\n",
      "loss: 0.708544 [44800/60000]\n",
      "loss: 0.794741 [51200/60000]\n",
      "loss: 0.684988 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.012229     n\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.551377 [    0/60000]\n",
      "loss: 0.801939 [ 6400/60000]\n",
      "loss: 0.600495 [12800/60000]\n",
      "loss: 0.957262 [19200/60000]\n",
      "loss: 0.804892 [25600/60000]\n",
      "loss: 0.724498 [32000/60000]\n",
      "loss: 0.758536 [38400/60000]\n",
      "loss: 0.706785 [44800/60000]\n",
      "loss: 0.792887 [51200/60000]\n",
      "loss: 0.676744 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.012125     n\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.542316 [    0/60000]\n",
      "loss: 0.794268 [ 6400/60000]\n",
      "loss: 0.593747 [12800/60000]\n",
      "loss: 0.949477 [19200/60000]\n",
      "loss: 0.799267 [25600/60000]\n",
      "loss: 0.718827 [32000/60000]\n",
      "loss: 0.751611 [38400/60000]\n",
      "loss: 0.705255 [44800/60000]\n",
      "loss: 0.790955 [51200/60000]\n",
      "loss: 0.669210 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.012030     n\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.533958 [    0/60000]\n",
      "loss: 0.787199 [ 6400/60000]\n",
      "loss: 0.587332 [12800/60000]\n",
      "loss: 0.942113 [19200/60000]\n",
      "loss: 0.793810 [25600/60000]\n",
      "loss: 0.713366 [32000/60000]\n",
      "loss: 0.745189 [38400/60000]\n",
      "loss: 0.704174 [44800/60000]\n",
      "loss: 0.789048 [51200/60000]\n",
      "loss: 0.662095 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.011943     n\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.526076 [    0/60000]\n",
      "loss: 0.780802 [ 6400/60000]\n",
      "loss: 0.581446 [12800/60000]\n",
      "loss: 0.935199 [19200/60000]\n",
      "loss: 0.788752 [25600/60000]\n",
      "loss: 0.707941 [32000/60000]\n",
      "loss: 0.739425 [38400/60000]\n",
      "loss: 0.703461 [44800/60000]\n",
      "loss: 0.787065 [51200/60000]\n",
      "loss: 0.655254 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.011863     n\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.518698 [    0/60000]\n",
      "loss: 0.774896 [ 6400/60000]\n",
      "loss: 0.575927 [12800/60000]\n",
      "loss: 0.928828 [19200/60000]\n",
      "loss: 0.783859 [25600/60000]\n",
      "loss: 0.703114 [32000/60000]\n",
      "loss: 0.734256 [38400/60000]\n",
      "loss: 0.702974 [44800/60000]\n",
      "loss: 0.785106 [51200/60000]\n",
      "loss: 0.648930 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.011789     n\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.511842 [    0/60000]\n",
      "loss: 0.769556 [ 6400/60000]\n",
      "loss: 0.570672 [12800/60000]\n",
      "loss: 0.922663 [19200/60000]\n",
      "loss: 0.779322 [25600/60000]\n",
      "loss: 0.698566 [32000/60000]\n",
      "loss: 0.729485 [38400/60000]\n",
      "loss: 0.702701 [44800/60000]\n",
      "loss: 0.782879 [51200/60000]\n",
      "loss: 0.643000 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.011722     n\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.505410 [    0/60000]\n",
      "loss: 0.764847 [ 6400/60000]\n",
      "loss: 0.565868 [12800/60000]\n",
      "loss: 0.916996 [19200/60000]\n",
      "loss: 0.774712 [25600/60000]\n",
      "loss: 0.694297 [32000/60000]\n",
      "loss: 0.725390 [38400/60000]\n",
      "loss: 0.702477 [44800/60000]\n",
      "loss: 0.780521 [51200/60000]\n",
      "loss: 0.637188 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.011660     n\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.499070 [    0/60000]\n",
      "loss: 0.760656 [ 6400/60000]\n",
      "loss: 0.561457 [12800/60000]\n",
      "loss: 0.911826 [19200/60000]\n",
      "loss: 0.770451 [25600/60000]\n",
      "loss: 0.690260 [32000/60000]\n",
      "loss: 0.721456 [38400/60000]\n",
      "loss: 0.702111 [44800/60000]\n",
      "loss: 0.778026 [51200/60000]\n",
      "loss: 0.632073 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.011602     n\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.492963 [    0/60000]\n",
      "loss: 0.756735 [ 6400/60000]\n",
      "loss: 0.557275 [12800/60000]\n",
      "loss: 0.906934 [19200/60000]\n",
      "loss: 0.766543 [25600/60000]\n",
      "loss: 0.686490 [32000/60000]\n",
      "loss: 0.717611 [38400/60000]\n",
      "loss: 0.701880 [44800/60000]\n",
      "loss: 0.775300 [51200/60000]\n",
      "loss: 0.627113 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.011549     n\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.487127 [    0/60000]\n",
      "loss: 0.752930 [ 6400/60000]\n",
      "loss: 0.553248 [12800/60000]\n",
      "loss: 0.902246 [19200/60000]\n",
      "loss: 0.762417 [25600/60000]\n",
      "loss: 0.682837 [32000/60000]\n",
      "loss: 0.714027 [38400/60000]\n",
      "loss: 0.701738 [44800/60000]\n",
      "loss: 0.772676 [51200/60000]\n",
      "loss: 0.622443 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.011499     n\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.481689 [    0/60000]\n",
      "loss: 0.749359 [ 6400/60000]\n",
      "loss: 0.549468 [12800/60000]\n",
      "loss: 0.897848 [19200/60000]\n",
      "loss: 0.758641 [25600/60000]\n",
      "loss: 0.679357 [32000/60000]\n",
      "loss: 0.710941 [38400/60000]\n",
      "loss: 0.701545 [44800/60000]\n",
      "loss: 0.770149 [51200/60000]\n",
      "loss: 0.617882 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.011453     n\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.476449 [    0/60000]\n",
      "loss: 0.745834 [ 6400/60000]\n",
      "loss: 0.545806 [12800/60000]\n",
      "loss: 0.893349 [19200/60000]\n",
      "loss: 0.755084 [25600/60000]\n",
      "loss: 0.676165 [32000/60000]\n",
      "loss: 0.708072 [38400/60000]\n",
      "loss: 0.701227 [44800/60000]\n",
      "loss: 0.767548 [51200/60000]\n",
      "loss: 0.613594 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.011410     n\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.471497 [    0/60000]\n",
      "loss: 0.742501 [ 6400/60000]\n",
      "loss: 0.542437 [12800/60000]\n",
      "loss: 0.889319 [19200/60000]\n",
      "loss: 0.751402 [25600/60000]\n",
      "loss: 0.673219 [32000/60000]\n",
      "loss: 0.705290 [38400/60000]\n",
      "loss: 0.700838 [44800/60000]\n",
      "loss: 0.764879 [51200/60000]\n",
      "loss: 0.609721 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.011369     n\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.466729 [    0/60000]\n",
      "loss: 0.739421 [ 6400/60000]\n",
      "loss: 0.539280 [12800/60000]\n",
      "loss: 0.885431 [19200/60000]\n",
      "loss: 0.747737 [25600/60000]\n",
      "loss: 0.670226 [32000/60000]\n",
      "loss: 0.702683 [38400/60000]\n",
      "loss: 0.700390 [44800/60000]\n",
      "loss: 0.762140 [51200/60000]\n",
      "loss: 0.606039 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.011331     n\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.462055 [    0/60000]\n",
      "loss: 0.736474 [ 6400/60000]\n",
      "loss: 0.536303 [12800/60000]\n",
      "loss: 0.881960 [19200/60000]\n",
      "loss: 0.744210 [25600/60000]\n",
      "loss: 0.667444 [32000/60000]\n",
      "loss: 0.700190 [38400/60000]\n",
      "loss: 0.699834 [44800/60000]\n",
      "loss: 0.759389 [51200/60000]\n",
      "loss: 0.603193 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.011296     n\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.457582 [    0/60000]\n",
      "loss: 0.733605 [ 6400/60000]\n",
      "loss: 0.533663 [12800/60000]\n",
      "loss: 0.878423 [19200/60000]\n",
      "loss: 0.740589 [25600/60000]\n",
      "loss: 0.664665 [32000/60000]\n",
      "loss: 0.697686 [38400/60000]\n",
      "loss: 0.699242 [44800/60000]\n",
      "loss: 0.756676 [51200/60000]\n",
      "loss: 0.599964 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.011262     n\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.453243 [    0/60000]\n",
      "loss: 0.730917 [ 6400/60000]\n",
      "loss: 0.531035 [12800/60000]\n",
      "loss: 0.875207 [19200/60000]\n",
      "loss: 0.737278 [25600/60000]\n",
      "loss: 0.661941 [32000/60000]\n",
      "loss: 0.695340 [38400/60000]\n",
      "loss: 0.698558 [44800/60000]\n",
      "loss: 0.753886 [51200/60000]\n",
      "loss: 0.596972 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.011229     n\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.449183 [    0/60000]\n",
      "loss: 0.728283 [ 6400/60000]\n",
      "loss: 0.528481 [12800/60000]\n",
      "loss: 0.872097 [19200/60000]\n",
      "loss: 0.734057 [25600/60000]\n",
      "loss: 0.659298 [32000/60000]\n",
      "loss: 0.693165 [38400/60000]\n",
      "loss: 0.697853 [44800/60000]\n",
      "loss: 0.751152 [51200/60000]\n",
      "loss: 0.594039 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.011199     n\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.445238 [    0/60000]\n",
      "loss: 0.725759 [ 6400/60000]\n",
      "loss: 0.526037 [12800/60000]\n",
      "loss: 0.869311 [19200/60000]\n",
      "loss: 0.730930 [25600/60000]\n",
      "loss: 0.656744 [32000/60000]\n",
      "loss: 0.690990 [38400/60000]\n",
      "loss: 0.697076 [44800/60000]\n",
      "loss: 0.748488 [51200/60000]\n",
      "loss: 0.591377 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.011169     n\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.441402 [    0/60000]\n",
      "loss: 0.723279 [ 6400/60000]\n",
      "loss: 0.523900 [12800/60000]\n",
      "loss: 0.866645 [19200/60000]\n",
      "loss: 0.727873 [25600/60000]\n",
      "loss: 0.654177 [32000/60000]\n",
      "loss: 0.688879 [38400/60000]\n",
      "loss: 0.696198 [44800/60000]\n",
      "loss: 0.745798 [51200/60000]\n",
      "loss: 0.588878 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.011142     n\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.437720 [    0/60000]\n",
      "loss: 0.720877 [ 6400/60000]\n",
      "loss: 0.521735 [12800/60000]\n",
      "loss: 0.863925 [19200/60000]\n",
      "loss: 0.724929 [25600/60000]\n",
      "loss: 0.651811 [32000/60000]\n",
      "loss: 0.686738 [38400/60000]\n",
      "loss: 0.694985 [44800/60000]\n",
      "loss: 0.743072 [51200/60000]\n",
      "loss: 0.586578 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.011115     n\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"data/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51d2dbc107e90016ff58d506d19dfa66132cafa2ebfedbf9f4d98cf0f5094b18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
